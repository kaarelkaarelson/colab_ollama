# Colab Ollama

## 1. Install Ollama on your computer

[https://ollama.com/download](https://ollama.com/download)

## 2. Make ngrok account and generate a token.

[https://ngrok.com/](https://ngrok.com/)

## 3. Upload colab_ollama.ipynb to your google drive to utilize GPU.

Add ngrok token to the notebook.

Run the notebook and copy the ngrok tunnel URL. 

## 4. Connect to ngrok tunnel locally.

Pull the embedding/llm model first. 

Then use Langchain Ollama class to seamlessly use inference.


